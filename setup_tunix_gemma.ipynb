{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df79b7d4",
   "metadata": {},
   "source": [
    "# Tunix Gemma Setup\n",
    "This notebook prepares a Gemma checkpoint for Tunix-based supervised fine-tuning and GRPO experiments on Kaggle TPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6f95c",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Install Tunix and required libraries on the TPU runtime.\n",
    "- Authenticate with Hugging Face to download Gemma checkpoints.\n",
    "- Load tokenizer and model in Flax/JAX with bf16 precision.\n",
    "- Scaffold Tunix supervised and GRPO trainers ready for custom datasets and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Environment bootstrap\n",
    "!pip install --quiet \"google-tunix[prod]\" flax transformers accelerate datasets sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1847f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Imports and runtime checks\n",
    "import os\n",
    "import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from transformers import AutoTokenizer, FlaxAutoModelForCausalLM\n",
    "import tunix\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "jax.random.key(SEED)\n",
    "\n",
    "devices = jax.devices()\n",
    "print(f\"Detected {len(devices)} JAX device(s).\")\n",
    "print(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Hugging Face authentication helpers\n",
    "import getpass\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = getpass.getpass(\"Enter your Hugging Face token (read access only): \")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_HOME\"] = os.environ.get(\"HF_HOME\", \"/kaggle/temp/hf-cache\")\n",
    "\n",
    "MODEL_NAME = \"google/gemma-2-2b-it\"  # swap to base Gemma variant if desired\n",
    "TOKENIZER_NAME = MODEL_NAME\n",
    "print(f\"Using checkpoint: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Load tokenizer and base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, token=HF_TOKEN)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "model = FlaxAutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=HF_TOKEN,\n",
    "    dtype=jnp.bfloat16,\n",
    "    _do_init=False,\n",
    ")\n",
    "\n",
    "param_count = sum(p.size for p in jax.tree_util.tree_leaves(model.params))\n",
    "print(f\"Loaded model with ~{param_count / 1e6:.1f}M parameters in bf16.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Tunix supervised fine-tuning scaffold\n",
    "from datasets import load_dataset\n",
    "from tunix.training.supervised import SupervisedConfig, SupervisedTrainer\n",
    "\n",
    "DATASET_NAME = \"gsm8k\"\n",
    "dataset = load_dataset(DATASET_NAME, \"main\", split=\"train[:128]\")\n",
    "\n",
    "def format_example(example):\n",
    "    prompt = f\"Question: {example['question']}\\nPlease think step by step before answering.\"\n",
    "    answer = example[\"answer\"].split(\"####\")[-1].strip()\n",
    "    target = f\"<reasoning>{example['answer']}</reasoning><answer>{answer}</answer>\"\n",
    "    return {\"prompt\": prompt, \"response\": target}\n",
    "\n",
    "processed_dataset = dataset.map(format_example, remove_columns=dataset.column_names)\n",
    "\n",
    "sft_config = SupervisedConfig(\n",
    "    learning_rate=1e-5,\n",
    "    max_steps=10,\n",
    "    per_device_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_seq_length=768,\n",
    "    output_dir=\"/kaggle/working/tunix-sft-checkpoints\",\n",
    "    logging_steps=1,\n",
    " )\n",
    "\n",
    "sft_trainer = SupervisedTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    config=sft_config,\n",
    "    train_dataset=processed_dataset,\n",
    " )\n",
    "\n",
    "print(\"Supervised trainer initialized — ready for warmup runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227246c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — GRPO configuration preview\n",
    "from tunix.training.rl import GRPOConfig, GRPOTrainer\n",
    "from tunix.rewards import basic_trace_reward\n",
    "\n",
    "grpo_config = GRPOConfig(\n",
    "    learning_rate=5e-6,\n",
    "    kl_weight=0.1,\n",
    "    num_generations=4,\n",
    "    max_prompt_length=512,\n",
    "    max_response_length=512,\n",
    "    total_training_steps=50,\n",
    "    logging_steps=5,\n",
    " )\n",
    "\n",
    "grpo_trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    reward_fn=basic_trace_reward,\n",
    "    config=grpo_config,\n",
    "    prompt_dataset=processed_dataset,\n",
    " )\n",
    "\n",
    "print(\"GRPO trainer scaffold ready — plug in custom rewards before training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611650de",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Replace the placeholder GSM8k slice with the custom curated dataset.\n",
    "- Swap in the process-aware reward function before launching GRPO training.\n",
    "- Promote this notebook to Kaggle once verified end-to-end on TPU."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
